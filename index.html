<html><head>
	<title>Pengwei Liang's Homepage</title>
	<style type="text/css">
	body {
		margin-top: 30px;
		margin-bottom: 30px;
		margin-left: 100px;
		margin-right: 100px;
	}
	p {
		margin-top: 0px;
		margin-bottom: 0px;
	}
	
	.caption {
		font-size: 34px;
		font-weight: normal;
		color: #000;
		font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
	}
	.caption-1 {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
	}
	.caption-2 {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		font-weight: bold;
		color: #234A8C;
	}
	.caption-3 {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		font-weight: bold;
		color: #F00;
	}
	
	.caption-4 {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		color: #234A8C;
	}
	.content {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		text-align: justify;
	}
	.content a {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		color: #000;
	}
	.content strong a {
		font-size: 16px;
		font-family: Tahoma, Geneva, sans-serif;
		color: #234A8C;
	}
	.title-small {
		font-size: 20px;
		font-family: Georgia, "Times New Roman", Times, serif;
		font-weight: bold;
		color: #F90;
	}
	.title-large {
		font-size: 28px;
		font-family: Georgia, "Times New Roman", Times, serif;
		font-weight: bold;
		color: #000;
	}
	.margin {
		font-size: 10px;
		line-height: 10px;
	}
	.margin-small {
		font-size: 5px;
		line-height: 5px;
	}
	.margin-large {
		font-size: 16px;
		line-height: 16px;
	}
	a:link {
		text-decoration: none;
	}
	a:visited {
		text-decoration: none;
	}
	content a:link {
		text-decoration: none;
	}
	content a:visited {
		text-decoration: none;
	}
	a:hover {
		text-decoration: underline;
	}
	a:active {
		text-decoration: underline;
		color: #000000;
		font-family: Tahoma, Geneva, sans-serif;
	}
	strong a:active {
		text-decoration: underline;
		color: #000000;
	}
	img
	{
	 border-color: black;
	}
	
	
	</style>
	<meta http-equiv="Content-Type" content="text/html; charset=gbk">
	</head>
	
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	
	  ga('create', 'UA-53682931-1', 'auto');
	  ga('send', 'pageview');
	
	</script>
	
	<body>
	
	<table border="0" width="100%">
	  <tbody>
	
		<tr>
	
		<td width="300"><table>
				<tr><td>
				<a href="imgs/me.jpg"><img src="imgs/me.jpg"  height="270" alt="Pengwei Liang; Hong Kong" border=1></td></tr>
				</table></td>
		<td width="15"></td>
		<td></td>
		<td><table border="0" width="100%">
		  <tbody><tr height="20">
			<td colspan="2"></td></tr>
	   <tr height="60">
			<td>
				   <p class="caption">Pengwei Liang<br><br></p>
				   <p class="content">Ph.D.</p>
				<p class="content">Computer Science and Technology</p>
				  <p class="content">School of Computer Science and Technology</p>
				<p class="content">Harbin Institute of Technology</p><br>
				<p class="content"><strong>Email</strong>: erfect2020@gmail.com</p>
			</td>
		  </tr>
	
	
	
		  <tr height="40">
			<td>
			  <p class="margin">&nbsp;</p>
			  <p class="content"><strong>
				  <a href="papers/cszx_cv.pdf">CV</a></strong>  |
				  <strong><a href="https://scholar.google.com/citations?user=54Ci0_0AAAAJ">Google Scholar</a></strong> |
				  <strong><a href="https://github.com/erfect2020/">GitHub</a></strong> |
				  <strong><a href="#sect-publications">Papers</a></strong> |
				  <!-- <strong><a href="./papers/research_statement.pdf">Research Statement</a></strong> | -->
				  <!-- <strong><a href="pdf/thesis_highres.pdf">Thesis</a></strong> | -->
				  <!-- <strong><a href="#sect-teaching">Teaching</a></strong></p> -->
			<!-- <p class="content"><strong>
				<a href="#sect-software">Software</a></strong> |
				<strong><a href="#sect-publications">Papers</a></strong> |
				<strong><a href="#sect-talks">Talks</a></strong> |
				<strong><a href="#sect-awards">Awards</a></strong> |
				<strong><a href="https://arxiv.org/a/zhu_j_5.html">Arxiv</a></strong>
			</p> -->
			</td>
		  </tr>
		  <tr height="20">
			<td colspan="2"></td></tr>
		</tbody></table></td>
	  </tr>
	</tbody></table>
	<p class="margin">&nbsp;</p>
	
	<table border="0" >
	  <tbody>
		<tr>
		  <td width="900"> <p align="justify" class="content">I am a Ph.D. student at Harbin Institute of Technology, advised by <strong><a href="https://homepage.hit.edu.cn/jiangjunjun" target="_blank" rel="nofollow" class="caption-2">Prof. Junjun Jiang</a></strong> and <strong><a href="https://sites.google.com/site/jiayima2013/jiayi-ma-%E9%A9%AC%E4%BD%B3%E4%B9%89-professor" target="_blank" rel="nofollow" class="caption-2">Prof. Jiayi Ma</a></strong>. I obtained my M.S. from Wuhan University. My research focuses on image generation (AIGC), image restoration, and image editing with LLMs. These areas have broad applications, including generative AI and low-level visual enhancement.</p>
		  </tr>
	  </tbody>
	</table>
	
	<br>
	<br>
	
	
	<p id="sect-publications" class="title-large">Publications</p>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/alf_ntl.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>FusionGAN: A generative adversarial network for infrared and visible image fusion.</strong></p>
		<p class="content">
			<a href="https://sites.google.com/site/jiayima2013/jiayi-ma-%E9%A9%AC%E4%BD%B3%E4%B9%89-professor">Jiayi Ma</a>,
			<a href="https://scholar.google.com/citations?user=VylFolAAAAAJ"> Wei Yu</a>,
			<a href="http://erfect2020.github.io/"><b>Pengwei Liang</b></a>, 
			<a href="https://scholar.google.com/citations?user=Fq0h6mcAAAAJ">Chang Li</a>, 
			<a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>
		</p>
		<p class="content">Information Fusion, 2019 (cition:2122)</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://github.com/jiayi-ma/FusionGAN">Project</a></strong> |
				<strong> <a href="https://github.com/jiayi-ma/FusionGAN">Code</a></strong> |
				<strong><a href="https://www.sciencedirect.com/science/article/pii/S1566253518301143
					">Paper</a></strong> |
			    <strong><a href="bib/FusionGAN.bib" download>BibTeX</a></strong>
				<br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://erfect2020.github.io/"><img src="imgs/alf.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>BaMBNet: A blur-aware multi-branch network for dual-pixel defocus deblurring.</strong></p>
		<p class="content"><a href="http://erfect2020.github.io/"><b>Pengwei Liang</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu*</a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>, <a href="https://sfb.kaust.edu.sa/Pages/Gao.aspx">Xin Gao</a>, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">IEEE/CAA Journal of Automatica Sinica (JAS), 2022</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://github.com/hitcszx/ALFs">Project</a></strong> |
				<strong> <a href="https://github.com/hitcszx/ALFs">Code</a></strong> |
				<strong><a href="http://arxiv.org/abs/2106.03110">Paper</a></strong> |
				<strong><a href="https://icml.cc/media/icml-2021/Slides/8595.pdf">Slide</a></strong> |
				<strong><a href="https://github.com/hitcszx/ALFs#reference">BibTex</a></strong>
			<br> </p>  
	</tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/lnl_sr.png" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Fusion from Decomposition: A Self-Supervised Decomposition Approach for Image Fusion.</strong></p>
		<p class="content"><a href="http://erfect2020.github.io/"><b>Pengwei Liang</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu*</a>, <a href="https://chenyang4.github.io/">Chenyang Wang</a>, <a href="http://homepage.hit.edu.cn/zhaideming">Deming Zhai</a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">European Conference on Computer Vision (ECCV), 2022</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://github.com/hitcszx/lnl_sr">Project</a></strong> |
				<strong> <a href="https://github.com/hitcszx/lnl_sr">Code</a></strong> |
				<strong><a href="http://arxiv.org">Paper</a></strong> |
				<strong> <a href="slides/iccv2021.pdf">Slide</a></strong> |
				<strong><a href="https://github.com/hitcszx/lnl_sr#reference">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://openreview.net/forum?id=V3PD4JzZEGk"><img src="imgs/ball.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Image Deblurring by Exploring In-depth Properties of Transformer.</strong></p>
		<p class="content"><a href="http://erfect2020.github.io/"><b>Pengwei Liang</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu*</a>, <a href="http://homepage.hit.edu.cn/zhaideming">Deming Zhai</a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>, <a href="https://sfb.kaust.edu.sa/Pages/Gao.aspx">Xin Gao</a>, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2024</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://openreview.net/forum?id=V3PD4JzZEGk">Project</a></strong> |
				<strong> <a href="https://openreview.net/forum?id=V3PD4JzZEGk">Code</a></strong> |
				<strong><a href="https://openreview.net/pdf?id=hqkhcFHOeKD">Paper</a></strong> |
				<strong><a href="https://iclr.cc/media/iclr-2022/Slides/5901.pdf">Slide</a></strong> |
				<strong><a href="https://openreview.net/forum?id=hqkhcFHOeKD#">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/pal.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Decoupling Image Deblurring into Twofold: A Hierarchical Model for Defocus Deblurring.</strong></p>
		<p class="content"><a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu*</a>, <a href="http://homepage.hit.edu.cn/zhaideming">Deming Zhai</a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>, <a href="https://sfb.kaust.edu.sa/Pages/Gao.aspx">Xin Gao</a>, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">IEEE Transactions on Computational Imaging (TCI), 2024</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://github.com/hitcszx/ALFs">Project</a></strong> |
				<strong> <a href="https://media.icml.cc/Conferences/ICML2022/supplementary/zhou22f-supp.zip">Code</a></strong> |
				<strong><a href="https://proceedings.mlr.press/v162/zhou22f/zhou22f.pdf">Paper</a></strong> |
				<strong><a href="https://icml.cc/media/icml-2022/Slides/17178.pdf">Slide</a></strong> |
				<strong><a href="https://proceedings.mlr.press/v162/zhou22f.html#:~:text=Copy%20to%20Clipboard-,Download,-Endnote">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/resmooth.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>FusionINV: A DiffusionBased Approach for Multi-Modal Image Fusion.</strong></p>
			<p class="content"> <a href="https://chenyang4.github.io/"><b>Chenyang Wang</b></a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang*</a>, <a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu</a>
		</p>
		<p class="content">IEEE Transactions on Image Processing (TIP), 2025.</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://github.com/hitcszx/ALFs">Project</a></strong> |
				<strong> <a href="https://github.com/Chenyang4/ReSmooth">Code</a></strong> |
				<strong><a href="https://arxiv.org/abs/2205.12606
					">Paper</a></strong> |
				<strong><a href="https://ieeexplore.ieee.org/document/9961105#:~:text=Cite-,This,-PDF">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/dynamics.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Pixel2Pixel: A Pixelwise Approach for Zero-Shot Single Image Denoising.</strong></p>
		<p class="content"><a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, <a href="http://homepage.hit.edu.cn/xmliu">Xianming Liu*</a>, <a href="http://homepage.hit.edu.cn/xmliu">Hanzhang Wang</a>, <a href="http://homepage.hit.edu.cn/zhaideming">Deming Zhai</a>, <a href="http://homepage.hit.edu.cn/jiangjunjun">Junjun Jiang</a>, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2025.</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://jmlr.org/papers/v24/23-0771.html">Project</a></strong> |
				<strong> <a href="https://jmlr.org/papers/v24/23-0771.html">Code</a></strong> |
				<strong><a href="https://jmlr.org/papers/volume24/23-0771/23-0771.pdf">Paper</a></strong> |
				<strong><a href="https://jmlr.org/papers/v24/23-0771.bib">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/v_laplace.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>MaeFuse: Transferring omni features with pretrained masked autoencoders for infrared and visible image fusion via guided training.</strong></p>
		<p class="content"><a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, Xianming Liu*, Feilong Zhang, Gang Wu, Deming Zhai, Junjun Jiang, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">IEEE Transactions on Image Processing (TIP), 2025.</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://openreview.net/forum?id=yeeVBMDAwy">Project</a></strong> |
				<strong> <a href="https://openreview.net/forum?id=yeeVBMDAwy">Code</a></strong> |
				<strong><a href="https://openreview.net/pdf?id=yeeVBMDAwy">Paper</a></strong> |
				<strong><a href="https://openreview.net/forum?id=yeeVBMDAwy">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/zero_specl.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Robust Test-Time Adaptation for Single Image Denoising Using Deep Gaussian Prior.</strong></p>
		<p class="content"><a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, Xianming Liu*, Hao Yu, Jialiang Wang, Zeke Xie, Junjun Jiang, <a href="http://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
		</p>
		<p class="content">International Conference on Computer Vision (ICCV) 2025</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://openreview.net/forum?id=RZBy8oHTz4">Project</a></strong> |
				<strong> <a href="https://openreview.net/forum?id=RZBy8oHTz4">Code</a></strong> |
				<strong><a href="https://openreview.net/pdf?id=RZBy8oHTz4">Paper</a></strong> |
				<strong><a href="https://openreview.net/forum?id=yeeVBMDAwy">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table>
	<!-- <table border="0">
	<tbody><tr>
		<td width="140"><a href="https://hitcszx.github.io/"><img src="imgs/nerf.jpg" border="1"width="210"></a></td>
		<td width="20"></td>
		<td valign="middle" width="900"><p class="content"><strong>Neural Field Classifiers via Target Encoding and Classification Loss</strong></p>
		<p class="content"> <b>Xindi Yang</b>, Zeke Xie, <a href="https://hitcszx.github.io/"><b>Xiong Zhou</b></a>, Boyu Liu, Buhua Liu, Yi Liu, Haoran Wang, YUNFENG CAI, Mingming Sun
		</p>
		<p class="content">International Conference on Learning Representations (ICLR) 2024</p>
			<p class="margin-small">&nbsp;</p>
		<p class="content">
		<strong><a href="https://openreview.net/forum?id=9NqC72m31m">Project</a></strong> |
				<strong> <a href="https://openreview.net/forum?id=9NqC72m31m">Code</a></strong> |
				<strong><a href="https://openreview.net/pdf?id=9NqC72m31m">Paper</a></strong> |
				<strong><a href="https://openreview.net/forum?id=9NqC72m31m">BibTex</a></strong> <br> </p>  </tr>
	</tbody>
	</table> -->
	<div style="display:none">
	
	<script type="text/javascript" src="http://gostats.com/js/counter.js"></script>
	<script type="text/javascript">_gos='c3.gostats.com';_goa=390583;
	_got=4;_goi=1;_goz=0;_god='hits';_gol='web page statistics from GoStats';_GoStatsRun();</script>
	
	</div>
	<br>
	<br>
	<p id="service" class="title-large">Service</p>
	<ul>
		<li><p class="content">Reviewer or PC member: ICML 2022/2024, ICLR 2022/2023/2024, NeurIPS 2022/2023, CVPR 2024, T-PAMI, T-NNLS</p></li>
		<li><p class="content">Outstanding Reviewer at ICML 2022 (top 10%)</p></li>
	</ul>
	<br>
	<br>
	<p id="sect-awards" class="title-large">Awards</p>
	<ul>
		<li><p class="content">Tencent Scholarship, 2022</p></li>
		<li><p class="content">China National Scholarship, 2022</p></li>
		<li><p class="content">Silver Medal in the 29th Chinese Mathematical Olympiad (CMO)</p></li>
	</ul>
	<div align="center" style="margin:auto;padding-top:10px">
            <div style="width:15%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=h87tkcVTteUC8QVeZ_wn1pK4-aVDcUQQqwJEgnZyQBI"></script>
            </div>
        </div>
	</body></html>
